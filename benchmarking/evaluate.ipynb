{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate a given model on a given benchmark\n",
    "\n",
    "Example:\n",
    "python evaluate.py --model_name birefnet --benchmark gcp_url_to_benchmark\n",
    "\n",
    "Gian Favero\n",
    "Ideogram\n",
    "2025-10-29\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/\")\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/BiRefNet/\")\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from BiRefNet.benchmarking.factory import get_model\n",
    "from BiRefNet.ideogram_dataset import BenchmarkDataset, EvalDataset\n",
    "from BiRefNet.ideogram_utils import pil_image_to_bytes, reduce_spill, recover_original_rgba\n",
    "from tfrecords.benchmark.tfr import BenchmarkExample\n",
    "from tfrecords.eval.tfr import EvalExample\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5289f4",
   "metadata": {},
   "source": [
    "### Functional code for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bg_removal_transform(sample): # from BiRefNet\n",
    "    transform_pipeline = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = sample[\"images\"][0] # PIL.Image\n",
    "    input_image = transform_pipeline(image) # Tensor (C, H, W) in the range [0.0, 1.0]\n",
    "    return image, input_image\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    input_images = [item[1] for item in batch]\n",
    "    input_images = torch.stack(input_images)\n",
    "    return {\"images\": images, \"input_images\": input_images}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
    "\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    for batch in dataloader:\n",
    "        input_images = batch[\"input_images\"].to(model.device).half() # needs to be full precision for rmbgv2\n",
    "        images = batch[\"images\"]\n",
    "\n",
    "        masks = model(input_images)\n",
    "        masks[masks < 0.1] = 0\n",
    "\n",
    "        images_list.extend(images)\n",
    "        masks_list.append(masks.detach().cpu())\n",
    "    masks_list = torch.cat(masks_list, dim=0)\n",
    "\n",
    "    output_list = []\n",
    "    for image, mask in zip(images_list, masks_list):\n",
    "        mask = transforms.ToPILImage()(mask)\n",
    "        mask = mask.resize(image.size)\n",
    "\n",
    "        recovered_rgba = recover_original_rgba(image, mask)\n",
    "        image = reduce_spill(recovered_rgba, mask, r=90)\n",
    "\n",
    "        image.putalpha(mask)\n",
    "\n",
    "        output_list.append(image)\n",
    "\n",
    "    return output_list\n",
    "\n",
    "def save_output(output_list, model_name, benchmark):\n",
    "    os.makedirs(f\"eval-output/{benchmark}/{model_name}\", exist_ok=True)\n",
    "    for i, output in enumerate(output_list):\n",
    "        output.save(f\"eval-output/{benchmark}/{model_name}/sample_{i}.png\")\n",
    "\n",
    "def write_output_to_tfr(output_list, benchmark_url, writer_name):\n",
    "    data = tf.data.TFRecordDataset(str(benchmark_url)).as_numpy_iterator()\n",
    "    with tf.io.TFRecordWriter(writer_name) as writer:\n",
    "        for image, serialized in zip(output_list, data):\n",
    "            ex = EvalExample.from_tf_example(serialized)\n",
    "            writer.write(\n",
    "                EvalExample(\n",
    "                    prompt=ex.prompt,\n",
    "                    images=[pil_image_to_bytes(image)]\n",
    "                ).to_tf_example().SerializeToString()\n",
    "            )\n",
    "    print(f\"Wrote {len(output_list)} eval examples to {writer_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ddb13",
   "metadata": {},
   "source": [
    "### Launch point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"custom\" # ['birefnet', 'rmbgv2', 'custom']\n",
    "benchmark = \"base-benchmark\" # ['green-benchmark', 'base-benchmark', 'ig-benchmark']\n",
    "path_to_weight = \"/home/gianfavero/projects/BiRefNet/ckpts/test/step_35648.pth\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating {model_name} on {benchmark}\")\n",
    "\n",
    "if benchmark == \"green-benchmark\":\n",
    "    benchmark_url = \"gs://mobius-dev-us-east5/gian_favero_workspace/background_removal_examples/11072025_green_graphic_bm_gian-green-graphic-2k.tfr\"\n",
    "elif benchmark == \"base-benchmark\":\n",
    "    benchmark_url = \"gs://mobius-dev-us-east5/gian_favero_workspace/background_removal_examples/11122025_bg_removal_bm_v3.tfr\"\n",
    "elif benchmark == \"ig-benchmark\":\n",
    "    benchmark_url = \"gs://mobius-dev-us-east5/gian_favero_workspace/background_removal_examples/10292025_samples.tfr\"\n",
    "\n",
    "tfr_dataset = EvalDataset( \n",
    "    writer_name=benchmark_url,\n",
    "    keys=[\"images\"],\n",
    "    transform=bg_removal_transform,\n",
    ")\n",
    "\n",
    "tfr_dataloader = DataLoader(\n",
    "    tfr_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model = get_model(model_name, device=device, path_to_weight=path_to_weight)\n",
    "\n",
    "output = evaluate(model, tfr_dataloader)\n",
    "\n",
    "writer_name = f\"gs://mobius-dev-us-east5/gian_favero_workspace/background_removal_examples/removed_{benchmark_url.split('/')[-1]}\"\n",
    "#write_output_to_tfr(output, benchmark_url, writer_name)\n",
    "\n",
    "save_output(output, model_name, benchmark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biref-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
