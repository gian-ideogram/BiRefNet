{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate a given model on a given benchmark\n",
    "\n",
    "Example:\n",
    "python evaluate.py --model_name birefnet --benchmark gcp_url_to_benchmark\n",
    "\n",
    "Gian Favero\n",
    "Ideogram\n",
    "2025-10-29\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/\")\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/BiRefNet/\")\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from BiRefNet.benchmarking.factory import get_model\n",
    "from BiRefNet.ideogram_utils import pil_image_to_bytes, reduce_spill, recover_original_rgba\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def nearest_color_average(img, target_mask, valid_source_mask, k=5):\n",
    "    ys, xs = np.nonzero(valid_source_mask)\n",
    "    if len(xs) == 0:\n",
    "        return img.copy()\n",
    "\n",
    "    # donor pixels\n",
    "    coords = np.column_stack([ys, xs])\n",
    "    tree = cKDTree(coords)\n",
    "\n",
    "    # target pixels (only pixels to replace)\n",
    "    ty, tx = np.nonzero(target_mask)\n",
    "    if len(tx) == 0:\n",
    "        return img.copy()\n",
    "    target_coords = np.column_stack([ty, tx])\n",
    "\n",
    "    # Query the k nearest donors\n",
    "    k = min(k, len(coords))\n",
    "    dists, idxs = tree.query(target_coords, k=k)\n",
    "    sampled_coords = coords[idxs]  # shape = (N_targets, k, 2)\n",
    "    sampled = img[sampled_coords[:,:,0], sampled_coords[:,:,1]]  # (N_targets, k, 3)\n",
    "\n",
    "    colors = np.median(sampled, axis=1)\n",
    "\n",
    "    # Apply replacement\n",
    "    result = img.copy()\n",
    "    result[ty, tx] = colors\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "\n",
    "def srgb_to_linear(c):\n",
    "    c = c / 255.0\n",
    "    return np.where(c <= 0.04045,\n",
    "                    c / 12.92,\n",
    "                    ((c + 0.055) / 1.055) ** 2.4)\n",
    "\n",
    "def edge_color_replace(fg_img, alpha, edge_thickness=5) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Remove green color spill from semi-transparent pixels near mask edges by replacing with nearest non-green opaque pixel.\n",
    "    \n",
    "    Args:\n",
    "        fg_img: PIL RGB image containing the foreground\n",
    "        alpha: PIL grayscale image containing the alpha channel (0-255 range)\n",
    "        edge_thickness: Number of pixels from the mask edge to apply the effect (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        PIL RGB image with green spill removed from edge regions\n",
    "    \"\"\"    \n",
    "    img = np.array(fg_img)\n",
    "    alpha = np.array(alpha).astype(np.uint8)\n",
    "\n",
    "    # Create binary mask for edge detection (opaque regions)\n",
    "    binary_mask = alpha > 0\n",
    "    \n",
    "    # Find edge region by dilating and eroding the mask\n",
    "    structure = np.ones((3, 3), dtype=bool)\n",
    "    dilated = binary_dilation(binary_mask, structure=structure, iterations=edge_thickness)\n",
    "    eroded = binary_erosion(binary_mask, structure=structure, iterations=edge_thickness)\n",
    "    edge_region = dilated & ~eroded\n",
    "    \n",
    "    # Identify green spill in edge areas\n",
    "    linear_img = srgb_to_linear(img)\n",
    "    R = linear_img[:, :, 0].astype(np.float32)\n",
    "    G = linear_img[:, :, 1].astype(np.float32)\n",
    "    B = linear_img[:, :, 2].astype(np.float32)\n",
    "    total = R + G + B + 1e-5\n",
    "    g_norm = G / total\n",
    "    g_dominance = g_norm - 1/3\n",
    "    is_green = g_dominance > 0.3\n",
    "    \n",
    "    # Identify green spill in interior areas\n",
    "    very_transparent_mask = alpha < 250 # we know these will have a green tinge\n",
    "    target_mask = edge_region & is_green & very_transparent_mask | very_transparent_mask & is_green\n",
    "\n",
    "    # Find valid source pixels (opaque and not green)\n",
    "    is_not_green = ~is_green\n",
    "    valid_source_mask = is_not_green & binary_mask\n",
    "    nearest_colors = nearest_color_average(img, target_mask, valid_source_mask)\n",
    "\n",
    "    # Replace only the target pixels\n",
    "    result = img.copy()\n",
    "    result[target_mask] = nearest_colors[target_mask]\n",
    "    result_pil = Image.fromarray(result.astype(np.uint8))\n",
    "\n",
    "    return result_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bg_removal_transform(sample): # from BiRefNet\n",
    "    transform_pipeline = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = PIL.Image.fromarray(sample) # np.ndarray (H, W, C)\n",
    "    input_image = transform_pipeline(image) # Tensor (C, H, W) in the range [0.0, 1.0]\n",
    "    return image, input_image\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    input_images = [item[1] for item in batch]\n",
    "    input_images = torch.stack(input_images)\n",
    "    return {\"images\": images, \"input_images\": input_images}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
    "\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    for batch in dataloader:\n",
    "        input_images = batch[\"input_images\"].to(model.device).half() # needs to be full precision for rmbgv2\n",
    "        images = batch[\"images\"]\n",
    "\n",
    "        masks = model(input_images)\n",
    "        masks[masks < 0.25] = 0\n",
    "\n",
    "        images_list.extend(images)\n",
    "        masks_list.append(masks.detach().cpu())\n",
    "    masks_list = torch.cat(masks_list, dim=0)\n",
    "\n",
    "    output_list = []\n",
    "    for image, mask in zip(images_list, masks_list):\n",
    "        mask = transforms.ToPILImage()(mask)\n",
    "        mask = mask.resize(image.size)\n",
    "\n",
    "        image = recover_original_rgba(image, mask)\n",
    "        image = reduce_spill(image, mask, r=90)\n",
    "        image = edge_color_replace(image.convert(\"RGB\"), mask)\n",
    "\n",
    "        image.putalpha(mask)\n",
    "\n",
    "        output_list.append(image)\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"custom\" # ['birefnet', 'rmbgv2', 'custom']\n",
    "benchmark = \"base-benchmark\" # ['green-benchmark', 'base-benchmark', 'ig-benchmark']\n",
    "path_to_weight = \"/home/gianfavero/projects/BiRefNet/ckpts/green_1e-5_cosine_matting/step_43186.pth\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# input dir\n",
    "# image_paths = [\"to_upscale/image_0.png\", \"to_upscale/image_1.png\", \"to_upscale/image_2.png\", \"to_upscale/image_3.png\", \"to_upscale/de_niro.png\"]\n",
    "image_paths = [os.path.join(\"to_upscale/\", f) for f in os.listdir(\"to_upscale/\") if f.endswith(\".png\")]\n",
    "for idx, path in enumerate(image_paths):\n",
    "    # Load the upscaled image for testing (\"upscaled.png\")\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    img_np = np.array(image)\n",
    "\n",
    "    # Get tile size and the shape of the image\n",
    "    tile_size = 1024 * 2\n",
    "    overlap = 16  # Overlap in pixels (adjust as needed, e.g., 128, 256, etc.)\n",
    "    stride = tile_size - overlap\n",
    "    h, w = img_np.shape[0], img_np.shape[1]\n",
    "\n",
    "    # Create tiles with overlap and track their positions\n",
    "    tiles = []\n",
    "    tile_positions = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            # Extract tile, handling boundaries\n",
    "            y_end = min(y + tile_size, h)\n",
    "            x_end = min(x + tile_size, w)\n",
    "            tile = img_np[y:y_end, x:x_end]\n",
    "            \n",
    "            tile = bg_removal_transform(tile)\n",
    "            tiles.append(tile)\n",
    "            tile_positions.append((x, y, x_end - x, y_end - y))  # (x, y, width, height)\n",
    "\n",
    "    # Make a dataloader for the tiles\n",
    "    dataloader = DataLoader(tiles, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model = get_model(model_name, device=device, path_to_weight=path_to_weight)\n",
    "    start_time = time.time()\n",
    "    output_list = evaluate(model, dataloader)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Function to create a feather mask for blending\n",
    "    def create_feather_mask(width, height, feather_size):\n",
    "        \"\"\"Create a feather mask with soft edges for blending\"\"\"\n",
    "        mask = np.ones((height, width), dtype=np.float32)\n",
    "        \n",
    "        # Apply feathering on all edges\n",
    "        for i in range(feather_size):\n",
    "            alpha = i / feather_size\n",
    "            # Top edge\n",
    "            if i < height:\n",
    "                mask[i, :] = np.minimum(mask[i, :], alpha)\n",
    "            # Bottom edge\n",
    "            if height - 1 - i >= 0:\n",
    "                mask[height - 1 - i, :] = np.minimum(mask[height - 1 - i, :], alpha)\n",
    "            # Left edge\n",
    "            if i < width:\n",
    "                mask[:, i] = np.minimum(mask[:, i], alpha)\n",
    "            # Right edge\n",
    "            if width - 1 - i >= 0:\n",
    "                mask[:, width - 1 - i] = np.minimum(mask[:, width - 1 - i], alpha)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    # Stitch the output tiles back together with blending\n",
    "    output_image = np.zeros((h, w, 4), dtype=np.float32)\n",
    "    weight_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    feather_size = overlap // 2  # Feather half of the overlap region\n",
    "\n",
    "    for (x, y, tile_w, tile_h), output in zip(tile_positions, output_list):\n",
    "        # Convert PIL image to numpy array\n",
    "        tile_array = np.array(output).astype(np.float32)\n",
    "        \n",
    "        # Create feather mask for this tile\n",
    "        feather_mask = create_feather_mask(tile_w, tile_h, feather_size)\n",
    "        \n",
    "        # Apply the feather mask to the tile\n",
    "        for c in range(4):  # RGBA channels\n",
    "            output_image[y:y+tile_h, x:x+tile_w, c] += tile_array[:, :, c] * feather_mask\n",
    "        \n",
    "        # Accumulate weights\n",
    "        weight_map[y:y+tile_h, x:x+tile_w] += feather_mask\n",
    "\n",
    "    # Normalize by the weight map to get the final blended result\n",
    "    for c in range(4):\n",
    "        output_image[:, :, c] = np.divide(\n",
    "            output_image[:, :, c], \n",
    "            weight_map, \n",
    "            out=np.zeros_like(output_image[:, :, c]), \n",
    "            where=weight_map != 0\n",
    "        )\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    output_image = Image.fromarray(output_image.astype(np.uint8), mode='RGBA')\n",
    "\n",
    "    output_image.save(f\"sample_{idx}.png\")\n",
    "\n",
    "    print(f\"Processed {len(output_list)} overlapping tiles with {overlap}px overlap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biref-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
