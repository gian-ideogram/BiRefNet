{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate a given model on a given benchmark\n",
    "\n",
    "Example:\n",
    "python evaluate.py --model_name birefnet --benchmark gcp_url_to_benchmark\n",
    "\n",
    "Gian Favero\n",
    "Ideogram\n",
    "2025-10-29\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/\")\n",
    "sys.path.insert(0, \"/home/gianfavero/projects/BiRefNet/\")\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from BiRefNet.benchmarking.factory import get_model\n",
    "from BiRefNet.ideogram_utils import pil_image_to_bytes, reduce_spill, recover_original_rgba\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bg_removal_transform(sample): # from BiRefNet\n",
    "    transform_pipeline = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = PIL.Image.fromarray(sample) # np.ndarray (H, W, C)\n",
    "    input_image = transform_pipeline(image) # Tensor (C, H, W) in the range [0.0, 1.0]\n",
    "    return image, input_image\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    input_images = [item[1] for item in batch]\n",
    "    input_images = torch.stack(input_images)\n",
    "    return {\"images\": images, \"input_images\": input_images}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
    "\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    for batch in dataloader:\n",
    "        input_images = batch[\"input_images\"].to(model.device).half() # needs to be full precision for rmbgv2\n",
    "        images = batch[\"images\"]\n",
    "\n",
    "        masks = model(input_images)\n",
    "        masks[masks < 0.1] = 0\n",
    "\n",
    "        images_list.extend(images)\n",
    "        masks_list.append(masks.detach().cpu())\n",
    "    masks_list = torch.cat(masks_list, dim=0)\n",
    "\n",
    "    output_list = []\n",
    "    for image, mask in zip(images_list, masks_list):\n",
    "        mask = transforms.ToPILImage()(mask)\n",
    "        mask = mask.resize(image.size)\n",
    "\n",
    "        recovered_rgba = recover_original_rgba(image, mask)\n",
    "        image = reduce_spill(recovered_rgba, mask, r=90)\n",
    "\n",
    "        image.putalpha(mask)\n",
    "\n",
    "        output_list.append(image)\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"custom\" # ['birefnet', 'rmbgv2', 'custom']\n",
    "benchmark = \"base-benchmark\" # ['green-benchmark', 'base-benchmark', 'ig-benchmark']\n",
    "path_to_weight = \"/home/gianfavero/projects/BiRefNet/ckpts/green_1e-5_cosine_matting/step_43186.pth\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# input dir\n",
    "image_paths = [f\"test_samples/monopoly.png\" for i in range(1)]\n",
    "for idx, path in enumerate(image_paths):\n",
    "    # Load the upscaled image for testing (\"upscaled.png\")\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    img_np = np.array(image)\n",
    "\n",
    "    # Get tile size and the shape of the image\n",
    "    tile_size = 1024 * 1\n",
    "    overlap = 128  # Overlap in pixels (adjust as needed, e.g., 128, 256, etc.)\n",
    "    stride = tile_size - overlap\n",
    "    h, w = img_np.shape[0], img_np.shape[1]\n",
    "\n",
    "    # Create tiles with overlap and track their positions\n",
    "    tiles = []\n",
    "    tile_positions = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            # Extract tile, handling boundaries\n",
    "            y_end = min(y + tile_size, h)\n",
    "            x_end = min(x + tile_size, w)\n",
    "            tile = img_np[y:y_end, x:x_end]\n",
    "            \n",
    "            tile = bg_removal_transform(tile)\n",
    "            tiles.append(tile)\n",
    "            tile_positions.append((x, y, x_end - x, y_end - y))  # (x, y, width, height)\n",
    "\n",
    "    # Make a dataloader for the tiles\n",
    "    dataloader = DataLoader(tiles, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model = get_model(model_name, device=device, path_to_weight=path_to_weight)\n",
    "    start_time = time.time()\n",
    "    output_list = evaluate(model, dataloader)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Function to create a feather mask for blending\n",
    "    def create_feather_mask(width, height, feather_size):\n",
    "        \"\"\"Create a feather mask with soft edges for blending\"\"\"\n",
    "        mask = np.ones((height, width), dtype=np.float32)\n",
    "        \n",
    "        # Apply feathering on all edges\n",
    "        for i in range(feather_size):\n",
    "            alpha = i / feather_size\n",
    "            # Top edge\n",
    "            if i < height:\n",
    "                mask[i, :] = np.minimum(mask[i, :], alpha)\n",
    "            # Bottom edge\n",
    "            if height - 1 - i >= 0:\n",
    "                mask[height - 1 - i, :] = np.minimum(mask[height - 1 - i, :], alpha)\n",
    "            # Left edge\n",
    "            if i < width:\n",
    "                mask[:, i] = np.minimum(mask[:, i], alpha)\n",
    "            # Right edge\n",
    "            if width - 1 - i >= 0:\n",
    "                mask[:, width - 1 - i] = np.minimum(mask[:, width - 1 - i], alpha)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    # Stitch the output tiles back together with blending\n",
    "    output_image = np.zeros((h, w, 4), dtype=np.float32)\n",
    "    weight_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    feather_size = overlap // 2  # Feather half of the overlap region\n",
    "\n",
    "    for (x, y, tile_w, tile_h), output in zip(tile_positions, output_list):\n",
    "        # Convert PIL image to numpy array\n",
    "        tile_array = np.array(output).astype(np.float32)\n",
    "        \n",
    "        # Create feather mask for this tile\n",
    "        feather_mask = create_feather_mask(tile_w, tile_h, feather_size)\n",
    "        \n",
    "        # Apply the feather mask to the tile\n",
    "        for c in range(4):  # RGBA channels\n",
    "            output_image[y:y+tile_h, x:x+tile_w, c] += tile_array[:, :, c] * feather_mask\n",
    "        \n",
    "        # Accumulate weights\n",
    "        weight_map[y:y+tile_h, x:x+tile_w] += feather_mask\n",
    "\n",
    "    # Normalize by the weight map to get the final blended result\n",
    "    for c in range(4):\n",
    "        output_image[:, :, c] = np.divide(\n",
    "            output_image[:, :, c], \n",
    "            weight_map, \n",
    "            out=np.zeros_like(output_image[:, :, c]), \n",
    "            where=weight_map != 0\n",
    "        )\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    output_image = Image.fromarray(output_image.astype(np.uint8), mode='RGBA')\n",
    "\n",
    "    output_image.save(f\"sample_{idx}.png\")\n",
    "\n",
    "    print(f\"Processed {len(output_list)} overlapping tiles with {overlap}px overlap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biref-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
